{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: 1st Iteration of Logistic Regression\n",
    "---\n",
    "#### Import libraries and read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_ab</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>selftext_word_count</th>\n",
       "      <th>selftext_char_count</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Anti-Haul Monthly April 23, 2020</td>\n",
       "      <td>Are you on a no buy? Trying to stick to a more...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>asianbeauty</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>132</td>\n",
       "      <td>Anti-Haul Monthly April 23, 2020 Are you on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lululi_lululi</td>\n",
       "      <td>After working with seasoned estheticians throu...</td>\n",
       "      <td>Through our own project ([Glowism] my friend a...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>asianbeauty</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>164</td>\n",
       "      <td>611</td>\n",
       "      <td>3798</td>\n",
       "      <td>After working with seasoned estheticians throu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                              title  \\\n",
       "0  AutoModerator                   Anti-Haul Monthly April 23, 2020   \n",
       "1  lululi_lululi  After working with seasoned estheticians throu...   \n",
       "\n",
       "                                            selftext  num_comments  score  \\\n",
       "0  Are you on a no buy? Trying to stick to a more...             0      1   \n",
       "1  Through our own project ([Glowism] my friend a...             4      1   \n",
       "\n",
       "     subreddit  is_ab  title_word_count  title_char_count  \\\n",
       "0  asianbeauty      1                 4                32   \n",
       "1  asianbeauty      1                24               164   \n",
       "\n",
       "   selftext_word_count  selftext_char_count  \\\n",
       "0                   22                  132   \n",
       "1                  611                 3798   \n",
       "\n",
       "                                       combined_text  \n",
       "0  Anti-Haul Monthly April 23, 2020 Are you on a ...  \n",
       "1  After working with seasoned estheticians throu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/explored_skincare.csv')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign $X$ and $y$ variables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'combined_text',\n",
    "    'num_comments',\n",
    "    'score',\n",
    "    'title_word_count',\n",
    "    'title_char_count',\n",
    "    'selftext_word_count',\n",
    "    'selftext_char_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df['is_ab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set and fit model\n",
    "---\n",
    "**The Model**\n",
    "\n",
    "After applying gridsearch on different combination of parameters, the first iteration of the Logistic Regression model performs best utilizing the following combination,\n",
    "- `penalty` of l2 (ridge regularization),\n",
    "- `ngram_range` between 1 - 2 words in a sequence when transforming text data into matrix format using `CountVectorizer`, and\n",
    "- `cv` of 5 folds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Define functions to grab each features separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = FunctionTransformer(lambda x: x.drop(columns = 'combined_text'), validate = False)\n",
    "\n",
    "category = FunctionTransformer(lambda x: x['combined_text'], validate = False)\n",
    "\n",
    "# Riley Dallas and/or Daniel Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Set a pipeline with transformers and an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_pipe', Pipeline([\n",
    "                ('selector', numeric),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "            ('category_pipe', Pipeline([\n",
    "                ('selector', category),\n",
    "                ('cvec', CountVectorizer())\n",
    "            ]))\n",
    "    ])),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Daniel Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Set parameters for gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'features__category_pipe__cvec__ngram_range' : [(1,2)],\n",
    "    'logreg__penalty' : ['l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Instantiate and fit gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('features',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('numeric_pipe',\n",
       "                                                                        Pipeline(memory=None,\n",
       "                                                                                 steps=[('selector',\n",
       "                                                                                         FunctionTransformer(accept_sparse=False,\n",
       "                                                                                                             check_inverse=True,\n",
       "                                                                                                             func=<function <lambda> at 0x1090dca70>,\n",
       "                                                                                                             inv_kw_args=None,\n",
       "                                                                                                             inverse_func=None,\n",
       "                                                                                                             kw_args=None,\n",
       "                                                                                                             validate=False)),\n",
       "                                                                                        ('ss',...\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'features__category_pipe__cvec__ngram_range': [(1, 2)],\n",
       "                         'logreg__penalty': ['l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, params, cv=5)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "---\n",
    "**Baseline score**\n",
    "If I randomly choose a class for any observation, I have a 50% chance of correctly getting y = 1. My model should at least beat this probability.\n",
    "\n",
    "**Accuracy Scores**\n",
    "\n",
    "The model performed suspiciously well on the first try with train and test accuracy scores that are above 90%, which means it is likely that there are certain keywords that distinguish the two subreddits easily.\n",
    "\n",
    "- Train Score: 0.996\n",
    "- Train Score: 0.938\n",
    "\n",
    "**Cofficient Weights of Features**\n",
    "\n",
    "After investigating the coefficient weights of the top 50 most distinguishing features, there are in deed keywords that are specific to AsianBeauty subreddits. For example, of acronyms of the subreddit (AB or ABers), asian beauty brand names, asian beauty stores (Jolse and Yesstyle) or asian country names (Japan and Korea) are obviously mentioned more in the Asian beauty subreddit than SkincareAddiction. \n",
    "\n",
    "Reflecting on the goal of the project, I want the chatroom to recommend accurately which subreddits have people with the same questions and concers. I'm confident that if our (chatroom) user knows about AsianBeauty subreddit or have questions about the 10 step *Korean* skincare routine, they would know where to go on reddit.com. Hence, I will add acronyms of the subreddit, asian beauty stores, and asian country names to a custom stopwords list along with other noise and filler words to better understand the types of beauty and skincare problems that our users have that are better often discussed in AsianBeauty subreddit in my next iteration of the model.\n",
    "\n",
    "However, I am keeping brand names in my model even though they are big tells because when considering the use case of the chatroom, a user might have a question about certain brands that they are not familiar with without knowing the roots of the brand (if it's asian or not). In this case, it would be beneficial to be able to recommend them to the right subreddit by having these keywords in my modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline score\n",
    "Randomly predicting a class for any observation will have a 50% chance of getting y = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500269\n",
       "0    0.499731\n",
       "Name: is_ab, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9998802753666567\n",
      "Train Score: 0.9455916681630454\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score: {gs.score(X_train, y_train)}')\n",
    "print(f'Train Score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = gs.best_estimator_.named_steps['logreg'].coef_[0]\n",
    "\n",
    "feature_names = ['num_comments','score','title_word_count','title_char_count','selftext_word_count','selftext_char_count'] + \\\n",
    "gs.best_estimator_.named_steps['features'].transformer_list[1][1].named_steps['cvec'].get_feature_names()\n",
    "\n",
    "coef_df = pd.DataFrame({'features': feature_names, \n",
    "              'coef' : coefficients,\n",
    "              'exp_coef': [np.exp(coef) for coef in coefficients]\n",
    "             })\n",
    "\n",
    "# Daniel Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "      <th>exp_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>score</td>\n",
       "      <td>4.179748</td>\n",
       "      <td>65.349351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144145</th>\n",
       "      <td>discussion</td>\n",
       "      <td>3.735036</td>\n",
       "      <td>41.889519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13137</th>\n",
       "      <td>ab</td>\n",
       "      <td>3.046533</td>\n",
       "      <td>21.042258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55787</th>\n",
       "      <td>asian</td>\n",
       "      <td>1.623538</td>\n",
       "      <td>5.071002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408414</th>\n",
       "      <td>removed</td>\n",
       "      <td>1.320767</td>\n",
       "      <td>3.746293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129413</th>\n",
       "      <td>cushion</td>\n",
       "      <td>1.008709</td>\n",
       "      <td>2.742058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67929</th>\n",
       "      <td>beauty</td>\n",
       "      <td>0.966811</td>\n",
       "      <td>2.629546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268647</th>\n",
       "      <td>korea</td>\n",
       "      <td>0.913609</td>\n",
       "      <td>2.493305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162158</th>\n",
       "      <td>essence</td>\n",
       "      <td>0.902441</td>\n",
       "      <td>2.465614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261078</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0.867564</td>\n",
       "      <td>2.381104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565659</th>\n",
       "      <td>yesstyle</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>2.310957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146694</th>\n",
       "      <td>do you</td>\n",
       "      <td>0.778819</td>\n",
       "      <td>2.178897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19746</th>\n",
       "      <td>actives</td>\n",
       "      <td>0.754934</td>\n",
       "      <td>2.127471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247987</th>\n",
       "      <td>innisfree</td>\n",
       "      <td>0.732175</td>\n",
       "      <td>2.079600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434814</th>\n",
       "      <td>sheet</td>\n",
       "      <td>0.718548</td>\n",
       "      <td>2.051452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_comments</td>\n",
       "      <td>0.705473</td>\n",
       "      <td>2.024804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228158</th>\n",
       "      <td>hg</td>\n",
       "      <td>0.699048</td>\n",
       "      <td>2.011836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268877</th>\n",
       "      <td>korean</td>\n",
       "      <td>0.679124</td>\n",
       "      <td>1.972150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65364</th>\n",
       "      <td>bb</td>\n",
       "      <td>0.665755</td>\n",
       "      <td>1.945960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122693</th>\n",
       "      <td>cosrx</td>\n",
       "      <td>0.664087</td>\n",
       "      <td>1.942716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186196</th>\n",
       "      <td>fluff</td>\n",
       "      <td>0.639361</td>\n",
       "      <td>1.895270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234243</th>\n",
       "      <td>http</td>\n",
       "      <td>0.634187</td>\n",
       "      <td>1.885488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295943</th>\n",
       "      <td>masks</td>\n",
       "      <td>0.621964</td>\n",
       "      <td>1.862583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436385</th>\n",
       "      <td>shop</td>\n",
       "      <td>0.621062</td>\n",
       "      <td>1.860904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301605</th>\n",
       "      <td>memebox</td>\n",
       "      <td>0.613079</td>\n",
       "      <td>1.846106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155298</th>\n",
       "      <td>edit</td>\n",
       "      <td>0.611954</td>\n",
       "      <td>1.844030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387434</th>\n",
       "      <td>product product</td>\n",
       "      <td>0.596797</td>\n",
       "      <td>1.816292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379809</th>\n",
       "      <td>post accutane</td>\n",
       "      <td>0.588855</td>\n",
       "      <td>1.801924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262646</th>\n",
       "      <td>jolse</td>\n",
       "      <td>0.577134</td>\n",
       "      <td>1.780928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436051</th>\n",
       "      <td>shiseido</td>\n",
       "      <td>0.573354</td>\n",
       "      <td>1.774209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225665</th>\n",
       "      <td>help removed</td>\n",
       "      <td>0.570966</td>\n",
       "      <td>1.769976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16740</th>\n",
       "      <td>accutane routine</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>1.769799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13960</th>\n",
       "      <td>abers</td>\n",
       "      <td>0.568001</td>\n",
       "      <td>1.764735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379791</th>\n",
       "      <td>post</td>\n",
       "      <td>0.558817</td>\n",
       "      <td>1.748604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308159</th>\n",
       "      <td>mizon</td>\n",
       "      <td>0.558411</td>\n",
       "      <td>1.747893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448324</th>\n",
       "      <td>snail</td>\n",
       "      <td>0.557239</td>\n",
       "      <td>1.745845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307210</th>\n",
       "      <td>missha</td>\n",
       "      <td>0.554078</td>\n",
       "      <td>1.740335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35612</th>\n",
       "      <td>ampoule</td>\n",
       "      <td>0.550782</td>\n",
       "      <td>1.734609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327472</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>1.690559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96092</th>\n",
       "      <td>care routine</td>\n",
       "      <td>0.523573</td>\n",
       "      <td>1.688048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567786</th>\n",
       "      <td>your</td>\n",
       "      <td>0.521094</td>\n",
       "      <td>1.683868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77040</th>\n",
       "      <td>biore</td>\n",
       "      <td>0.507883</td>\n",
       "      <td>1.661769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361410</th>\n",
       "      <td>pack</td>\n",
       "      <td>0.500494</td>\n",
       "      <td>1.649535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178337</th>\n",
       "      <td>favourite</td>\n",
       "      <td>0.495071</td>\n",
       "      <td>1.640615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154773</th>\n",
       "      <td>ebay</td>\n",
       "      <td>0.492850</td>\n",
       "      <td>1.636976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550290</th>\n",
       "      <td>where</td>\n",
       "      <td>0.488322</td>\n",
       "      <td>1.629580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381343</th>\n",
       "      <td>power</td>\n",
       "      <td>0.486921</td>\n",
       "      <td>1.627298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259431</th>\n",
       "      <td>items</td>\n",
       "      <td>0.484942</td>\n",
       "      <td>1.624080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242554</th>\n",
       "      <td>in japan</td>\n",
       "      <td>0.476586</td>\n",
       "      <td>1.610567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173018</th>\n",
       "      <td>eyeliner</td>\n",
       "      <td>0.472412</td>\n",
       "      <td>1.603858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                features      coef   exp_coef\n",
       "1                  score  4.179748  65.349351\n",
       "144145        discussion  3.735036  41.889519\n",
       "13137                 ab  3.046533  21.042258\n",
       "55787              asian  1.623538   5.071002\n",
       "408414           removed  1.320767   3.746293\n",
       "129413           cushion  1.008709   2.742058\n",
       "67929             beauty  0.966811   2.629546\n",
       "268647             korea  0.913609   2.493305\n",
       "162158           essence  0.902441   2.465614\n",
       "261078          japanese  0.867564   2.381104\n",
       "565659          yesstyle  0.837662   2.310957\n",
       "146694            do you  0.778819   2.178897\n",
       "19746            actives  0.754934   2.127471\n",
       "247987         innisfree  0.732175   2.079600\n",
       "434814             sheet  0.718548   2.051452\n",
       "0           num_comments  0.705473   2.024804\n",
       "228158                hg  0.699048   2.011836\n",
       "268877            korean  0.679124   1.972150\n",
       "65364                 bb  0.665755   1.945960\n",
       "122693             cosrx  0.664087   1.942716\n",
       "186196             fluff  0.639361   1.895270\n",
       "234243              http  0.634187   1.885488\n",
       "295943             masks  0.621964   1.862583\n",
       "436385              shop  0.621062   1.860904\n",
       "301605           memebox  0.613079   1.846106\n",
       "155298              edit  0.611954   1.844030\n",
       "387434   product product  0.596797   1.816292\n",
       "379809     post accutane  0.588855   1.801924\n",
       "262646             jolse  0.577134   1.780928\n",
       "436051          shiseido  0.573354   1.774209\n",
       "225665      help removed  0.570966   1.769976\n",
       "16740   accutane routine  0.570866   1.769799\n",
       "13960              abers  0.568001   1.764735\n",
       "379791              post  0.558817   1.748604\n",
       "308159             mizon  0.558411   1.747893\n",
       "448324             snail  0.557239   1.745845\n",
       "307210            missha  0.554078   1.740335\n",
       "35612            ampoule  0.550782   1.734609\n",
       "327472              nice  0.525059   1.690559\n",
       "96092       care routine  0.523573   1.688048\n",
       "567786              your  0.521094   1.683868\n",
       "77040              biore  0.507883   1.661769\n",
       "361410              pack  0.500494   1.649535\n",
       "178337         favourite  0.495071   1.640615\n",
       "154773              ebay  0.492850   1.636976\n",
       "550290             where  0.488322   1.629580\n",
       "381343             power  0.486921   1.627298\n",
       "259431             items  0.484942   1.624080\n",
       "242554          in japan  0.476586   1.610567\n",
       "173018          eyeliner  0.472412   1.603858"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values('exp_coef', ascending=False).head(50)\n",
    "\n",
    "# Daniel Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Top 50 Features to create custom stopwords in next model iteration\n",
    "---\n",
    "I'm building out the list of custom stopwords in the cleaning notebook (002_clean.ipynb) to be used in other notebooks, such as EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score',\n",
       " 'discussion',\n",
       " 'ab',\n",
       " 'asian',\n",
       " 'removed',\n",
       " 'cushion',\n",
       " 'beauty',\n",
       " 'korea',\n",
       " 'essence',\n",
       " 'japanese',\n",
       " 'yesstyle',\n",
       " 'do you',\n",
       " 'actives',\n",
       " 'innisfree',\n",
       " 'sheet',\n",
       " 'num_comments',\n",
       " 'hg',\n",
       " 'korean',\n",
       " 'bb',\n",
       " 'cosrx',\n",
       " 'fluff',\n",
       " 'http',\n",
       " 'masks',\n",
       " 'shop',\n",
       " 'memebox',\n",
       " 'edit',\n",
       " 'product product',\n",
       " 'post accutane',\n",
       " 'jolse',\n",
       " 'shiseido',\n",
       " 'help removed',\n",
       " 'accutane routine',\n",
       " 'abers',\n",
       " 'post',\n",
       " 'mizon',\n",
       " 'snail',\n",
       " 'missha',\n",
       " 'ampoule',\n",
       " 'nice',\n",
       " 'care routine',\n",
       " 'your',\n",
       " 'biore',\n",
       " 'pack',\n",
       " 'favourite',\n",
       " 'ebay',\n",
       " 'where',\n",
       " 'power',\n",
       " 'items',\n",
       " 'in japan',\n",
       " 'eyeliner',\n",
       " 'have you',\n",
       " 'atomy',\n",
       " 'news',\n",
       " 'japan',\n",
       " 'double',\n",
       " 'from amazon',\n",
       " 'your routine',\n",
       " 'western',\n",
       " 'www',\n",
       " 'asia',\n",
       " 'lenses',\n",
       " 'with an',\n",
       " 'perfect',\n",
       " 'img',\n",
       " 'deals',\n",
       " 'rice',\n",
       " 'to look',\n",
       " 'asian beauty',\n",
       " 'lightening',\n",
       " 'prone',\n",
       " 'hadalabo',\n",
       " '10 step',\n",
       " 'dewy',\n",
       " 'usually',\n",
       " 'shipping',\n",
       " 'cool',\n",
       " 'products',\n",
       " 'labo',\n",
       " 'ab products',\n",
       " 'sulwhasoo',\n",
       " 'brand',\n",
       " 'in korea',\n",
       " 'asian skincare',\n",
       " 'eyes',\n",
       " 'milk',\n",
       " 'the sun',\n",
       " 'laneige',\n",
       " '2nd',\n",
       " 'lighten',\n",
       " 'me out',\n",
       " 'watch',\n",
       " 'pink',\n",
       " 'combination',\n",
       " 'code',\n",
       " 'is my',\n",
       " 'have combination',\n",
       " 'fungal acne',\n",
       " 'chinese',\n",
       " 'com',\n",
       " 'nature',\n",
       " 'moist',\n",
       " 'of your',\n",
       " 'to help',\n",
       " 'cleansing oil',\n",
       " 'black friday',\n",
       " 'long time',\n",
       " 'neogen',\n",
       " 'step',\n",
       " 'face shop',\n",
       " 'daiso',\n",
       " 'fungal',\n",
       " 'purging or',\n",
       " 'something like',\n",
       " 'sticky',\n",
       " 'etude',\n",
       " 'me any',\n",
       " 'seoul',\n",
       " 'kbeauty',\n",
       " 'suitable',\n",
       " 'wondering how',\n",
       " 'shade',\n",
       " 'winter',\n",
       " 'you do',\n",
       " 'lipstick',\n",
       " 'the product',\n",
       " 'muji',\n",
       " 'about the',\n",
       " 'period',\n",
       " 'and do',\n",
       " 'do not',\n",
       " 'stay',\n",
       " 'whitening',\n",
       " 'products have',\n",
       " 'acne treatment',\n",
       " 'sweat',\n",
       " 'aloe',\n",
       " 'shopping',\n",
       " 'thick',\n",
       " 'good skin',\n",
       " 'so it',\n",
       " 'which',\n",
       " 'weather',\n",
       " 'asianbeauty',\n",
       " 'on some',\n",
       " '2017',\n",
       " 'cushions',\n",
       " 'tints',\n",
       " 'what other',\n",
       " 'on dry',\n",
       " 'skin lotion',\n",
       " 'things to',\n",
       " 'received',\n",
       " 'cc',\n",
       " 'starting to',\n",
       " 'beauty products',\n",
       " 'routine that',\n",
       " 'following',\n",
       " 'powder',\n",
       " 'sheet mask',\n",
       " 'derma',\n",
       " 'processing',\n",
       " 'melano',\n",
       " 'him',\n",
       " 'me and',\n",
       " 'out the',\n",
       " 'about this',\n",
       " 'waterproof',\n",
       " 'http www',\n",
       " 'peripera',\n",
       " 'codes',\n",
       " 'aging products',\n",
       " 'also',\n",
       " 'sebum',\n",
       " 'favorite',\n",
       " 'getting rid',\n",
       " 'discussion what',\n",
       " 'look',\n",
       " 'uno',\n",
       " 'price',\n",
       " 'cosmetics',\n",
       " 'version',\n",
       " 'climate',\n",
       " 'flaky skin',\n",
       " 'skinfood',\n",
       " 'wait',\n",
       " 'tint',\n",
       " 'skin removed',\n",
       " 'cica',\n",
       " 'tan',\n",
       " 'is just',\n",
       " 'recommendations are',\n",
       " 'hydrating toner',\n",
       " 'dull',\n",
       " '新疆宝石品质金丝玉手镯',\n",
       " 'appreciated',\n",
       " 'pieu',\n",
       " 'to be',\n",
       " 'specific',\n",
       " 'travel',\n",
       " 'post acne',\n",
       " 'skincare product',\n",
       " 'your hg',\n",
       " 'like my',\n",
       " 'kit',\n",
       " 'cheeks',\n",
       " 'question how',\n",
       " 'benton',\n",
       " 'like the',\n",
       " 'plastic surgery',\n",
       " 'masks and',\n",
       " 'bangs',\n",
       " 'you could',\n",
       " 'sunscreen that',\n",
       " 'soothe',\n",
       " 'product but',\n",
       " 'seller',\n",
       " 'what are',\n",
       " 'site',\n",
       " 'puffy',\n",
       " 'kojic',\n",
       " 'sale',\n",
       " 'masks for',\n",
       " 'free shipping',\n",
       " 'that also',\n",
       " 'through',\n",
       " 'tony moly',\n",
       " 'tony',\n",
       " 'of sun',\n",
       " 'moisture',\n",
       " 'korean skincare',\n",
       " 'dehydrated',\n",
       " 'what good',\n",
       " 'customs',\n",
       " 'are cosmetics',\n",
       " 'cosmetics really',\n",
       " 'out this',\n",
       " 'to ab',\n",
       " 'fine line',\n",
       " 'slowly',\n",
       " 'eyelash',\n",
       " 'tinted moisturizer',\n",
       " 'also is',\n",
       " 'pore',\n",
       " 'any good',\n",
       " 'finish',\n",
       " 'really useful',\n",
       " 'it doesn',\n",
       " 'skin type',\n",
       " 'etude house',\n",
       " 'skin condition',\n",
       " 'products for',\n",
       " 'klairs',\n",
       " 'within',\n",
       " 'currently',\n",
       " 'youtubers',\n",
       " 'complete',\n",
       " 'look for',\n",
       " 'for acne',\n",
       " 'eternalhairstyles',\n",
       " 'our',\n",
       " 'order',\n",
       " 'betaine',\n",
       " 'you tried',\n",
       " 'regimen',\n",
       " 'for something',\n",
       " 'to do',\n",
       " 'any reviews',\n",
       " 'sleeping',\n",
       " 'acne scars',\n",
       " 'to know',\n",
       " 'need help',\n",
       " 'anyone heard',\n",
       " 'bacteria',\n",
       " 'started getting',\n",
       " 'week and',\n",
       " 'in it',\n",
       " 'purchasing',\n",
       " 'scars ve',\n",
       " 'pih',\n",
       " 'mild',\n",
       " 'toner',\n",
       " 'type',\n",
       " 'just got',\n",
       " 'acne prone',\n",
       " 'ceramides',\n",
       " 'singapore',\n",
       " 'the cosrx',\n",
       " 'test test',\n",
       " 'kikumasamune',\n",
       " 'combination skin',\n",
       " 'long',\n",
       " 'packs',\n",
       " 'somewhere',\n",
       " 'moly',\n",
       " 'scinic',\n",
       " 'aqua',\n",
       " 'soko',\n",
       " 'it can',\n",
       " 'the moisture',\n",
       " 'honey',\n",
       " 'heimish',\n",
       " 'kojic acid',\n",
       " 'hauls',\n",
       " 'essence and',\n",
       " 'questions',\n",
       " 'so the',\n",
       " 'tried them',\n",
       " 'and looking',\n",
       " 'present',\n",
       " 'it before',\n",
       " 'use them',\n",
       " 'don have',\n",
       " 'recommendations for',\n",
       " 'to use',\n",
       " 'heavy',\n",
       " 'for all',\n",
       " 'motto or',\n",
       " 'rules when',\n",
       " 'me to',\n",
       " 'great for',\n",
       " 'asian skin',\n",
       " 'the oil',\n",
       " 'use that',\n",
       " 'cleansing',\n",
       " 'sunscreen what',\n",
       " 'fashion',\n",
       " 'ii',\n",
       " 'pimples regularly',\n",
       " 'more develop',\n",
       " 'local',\n",
       " 'bring',\n",
       " 'the ingredients',\n",
       " 'melano cc',\n",
       " 'to wash',\n",
       " 'general',\n",
       " 'malaysia',\n",
       " 'feels',\n",
       " 'part',\n",
       " 'item',\n",
       " 'prescription',\n",
       " 'right now',\n",
       " 'seems',\n",
       " 'dry flaky',\n",
       " 'toners',\n",
       " 'under my',\n",
       " 'inflammation',\n",
       " 'much about',\n",
       " 'dead',\n",
       " 'house',\n",
       " 'bee',\n",
       " 'the dry',\n",
       " 'dokodemo',\n",
       " 'of face',\n",
       " 'review of',\n",
       " 'for people',\n",
       " 'and need',\n",
       " 'fine',\n",
       " 'best face',\n",
       " 'on vitamin',\n",
       " 'some sun',\n",
       " 'color',\n",
       " 'amp x200b',\n",
       " 'x200b',\n",
       " 'this can',\n",
       " 'what product',\n",
       " 'surgery',\n",
       " 'google',\n",
       " 'physical',\n",
       " 'trends',\n",
       " 'yet',\n",
       " 'off',\n",
       " 'line',\n",
       " 'suitable for',\n",
       " 'tape',\n",
       " 'arbutin',\n",
       " 'out how',\n",
       " 'develop',\n",
       " 'beauty product',\n",
       " 'the help',\n",
       " 'canmake',\n",
       " 'this and',\n",
       " 'place',\n",
       " 'my body',\n",
       " 'treatment remedies',\n",
       " 'couldn find',\n",
       " 'to reddit',\n",
       " 'fun',\n",
       " 'after acne',\n",
       " 'buy',\n",
       " 'in asia',\n",
       " 'in tokyo',\n",
       " 'surprised',\n",
       " 'sk',\n",
       " 'similar to',\n",
       " 'develop small',\n",
       " 'meetup',\n",
       " 'and thought',\n",
       " 'order of',\n",
       " 'play',\n",
       " 'hada labo',\n",
       " 'best tinted',\n",
       " 'main',\n",
       " 'the biore',\n",
       " 'any help',\n",
       " 'your favourite',\n",
       " 'does it',\n",
       " 'which is',\n",
       " 'are your',\n",
       " 'and really',\n",
       " 'service',\n",
       " 'pop up',\n",
       " 'caused by',\n",
       " 'areas',\n",
       " 'though',\n",
       " 'really like',\n",
       " 'contains',\n",
       " 'reasons',\n",
       " 'up my',\n",
       " 'sellers',\n",
       " 'foaming cleanser',\n",
       " 'below',\n",
       " 'discuss',\n",
       " 'pores on',\n",
       " 'wishtrend',\n",
       " 'survey',\n",
       " 'anti haul',\n",
       " 'sk ii',\n",
       " 'routine but',\n",
       " 'thats',\n",
       " 'is the',\n",
       " 'the acne',\n",
       " 'soko glam',\n",
       " 'hgs',\n",
       " 'skin looked',\n",
       " 'throw',\n",
       " 'moisturizer under',\n",
       " 'one is',\n",
       " 'ex',\n",
       " 'video',\n",
       " 'on google',\n",
       " 'fatty',\n",
       " 'lines and',\n",
       " 'sad',\n",
       " 'treatment essence',\n",
       " 'acne care',\n",
       " 'purchase',\n",
       " 'newbie',\n",
       " 'if someone',\n",
       " 'moisturizer what',\n",
       " 'mascara',\n",
       " 'brightening',\n",
       " 'those who',\n",
       " 'my face',\n",
       " 'bb cream',\n",
       " 'how was',\n",
       " 'looks so',\n",
       " 'corsx',\n",
       " 'proven',\n",
       " 'hylamide',\n",
       " 'women',\n",
       " 'amazon',\n",
       " 'mess',\n",
       " 'sheet masks',\n",
       " 'the reasons',\n",
       " 'or your',\n",
       " 'cosmetic',\n",
       " 'day and',\n",
       " 'skincare just',\n",
       " 'trip',\n",
       " 'was it',\n",
       " 'help me',\n",
       " 'foot',\n",
       " 'wigs',\n",
       " 'feel really',\n",
       " 'on wet',\n",
       " 'kiku',\n",
       " 'boston',\n",
       " 'circles under',\n",
       " 'save',\n",
       " 'guys',\n",
       " 'and acne',\n",
       " 'silver watch',\n",
       " 'yes',\n",
       " 'purging',\n",
       " 'loves',\n",
       " 'caused',\n",
       " 'and when',\n",
       " 'physical sunscreen',\n",
       " 'be much',\n",
       " 'fermented',\n",
       " 'face looks',\n",
       " 'routine was',\n",
       " 'friday',\n",
       " 'length',\n",
       " 'zero',\n",
       " 'shampoo',\n",
       " 'not using',\n",
       " 'free',\n",
       " 'seems like',\n",
       " 'without',\n",
       " 'usa',\n",
       " 'rice water',\n",
       " 'all my',\n",
       " 'useful',\n",
       " 'has it',\n",
       " 'firming',\n",
       " 'as they',\n",
       " 'the inside',\n",
       " 'has anybody',\n",
       " 'fast',\n",
       " 'welcome',\n",
       " 'with hormonal',\n",
       " 'friend',\n",
       " 'scar redness',\n",
       " 'recommend me',\n",
       " 'masks to',\n",
       " 'great anti',\n",
       " 'ingredients to',\n",
       " 'you to',\n",
       " 'when it',\n",
       " 'looks',\n",
       " 'pretty good',\n",
       " 'stay on',\n",
       " 'product amp',\n",
       " 'skin lightening',\n",
       " 'can make',\n",
       " 'have that',\n",
       " 'good care',\n",
       " 'stores',\n",
       " 'are you',\n",
       " 'acne scar',\n",
       " 'to lighten',\n",
       " 'were',\n",
       " 'coupon',\n",
       " 'recently bought',\n",
       " 'best lotion',\n",
       " 'forward to',\n",
       " 'it feels',\n",
       " 'extensions',\n",
       " 'coverage',\n",
       " 'sokoglam',\n",
       " 'tested',\n",
       " 'under 15',\n",
       " 'green tea',\n",
       " 'hope',\n",
       " 'skin dry',\n",
       " 'from this',\n",
       " 'manage',\n",
       " 'in seoul',\n",
       " 'skin that',\n",
       " 'any better',\n",
       " 'costco',\n",
       " 'poor',\n",
       " 'blemish cream',\n",
       " 'research on',\n",
       " 'type and',\n",
       " 'months of',\n",
       " 'does anyone',\n",
       " 'essences',\n",
       " 'iope',\n",
       " 'my skin',\n",
       " 'skin or',\n",
       " 'no idea',\n",
       " 'it said',\n",
       " 'keep your',\n",
       " 'help is',\n",
       " 'then the',\n",
       " 'cc vitamin',\n",
       " 'option',\n",
       " 'if anyone',\n",
       " 'bother me',\n",
       " 'illuminating',\n",
       " 'processing img',\n",
       " 'contacts',\n",
       " 'it away',\n",
       " 'bone',\n",
       " 'group',\n",
       " 'more oily',\n",
       " 'ago but',\n",
       " 'because sometimes',\n",
       " 'teens',\n",
       " 'from them',\n",
       " 'are there',\n",
       " 'lighten them',\n",
       " 'underarms',\n",
       " 'whiteheads',\n",
       " 'laugh',\n",
       " 'acne marks',\n",
       " 'is what',\n",
       " 'routine products',\n",
       " 'next',\n",
       " 'healthy skin',\n",
       " 'bought it',\n",
       " 'had huge',\n",
       " 'it helped',\n",
       " 'giving',\n",
       " 'of things',\n",
       " 'your skin',\n",
       " 'know where',\n",
       " 'on carousell',\n",
       " 'carousell',\n",
       " 'sleeping pack',\n",
       " 'sorry',\n",
       " 'lotion help',\n",
       " 'humid',\n",
       " 'so wanted',\n",
       " 'minimum',\n",
       " 'my period',\n",
       " 'heard of',\n",
       " 'new',\n",
       " 'face cream',\n",
       " 'safe but',\n",
       " 'cleaning',\n",
       " 'check',\n",
       " 'often do',\n",
       " 'step skincare',\n",
       " 'let discuss',\n",
       " 'response',\n",
       " 'checkout',\n",
       " 'really want',\n",
       " 'gradient',\n",
       " 'acids',\n",
       " 'premium',\n",
       " 'are in',\n",
       " 'refund',\n",
       " 'use it',\n",
       " 'mac',\n",
       " 'hi guys',\n",
       " 'guess',\n",
       " 'illuminating cleansing',\n",
       " 'iso great',\n",
       " 'aging illuminating',\n",
       " 'useful for',\n",
       " 'acne cream',\n",
       " 'what about',\n",
       " 'would help',\n",
       " 'promising',\n",
       " 'reducing',\n",
       " 'tone',\n",
       " 'been trying',\n",
       " 'acne it',\n",
       " 'watched',\n",
       " 'cleansing face',\n",
       " 'and forehead',\n",
       " 'with dry',\n",
       " 'considered',\n",
       " 'fall',\n",
       " 'triple',\n",
       " 'start now',\n",
       " 'to bring',\n",
       " 'exfoliator for',\n",
       " 'depot',\n",
       " 'foam',\n",
       " 'sun cream',\n",
       " 'back to',\n",
       " 'sunscreen pm',\n",
       " 've looked',\n",
       " 'pcos',\n",
       " 'aka',\n",
       " 'with redness',\n",
       " 'hey guys',\n",
       " 'clean my',\n",
       " 'you like',\n",
       " 'the first',\n",
       " 'hong',\n",
       " 'eyelid',\n",
       " '13',\n",
       " 'it however',\n",
       " 'aloe free',\n",
       " 'makeup',\n",
       " 'products on',\n",
       " 'rashes',\n",
       " 'yellow',\n",
       " 'jart',\n",
       " 'thailand',\n",
       " '10000',\n",
       " 'triggers',\n",
       " 'products removed',\n",
       " 'comes to',\n",
       " 'shops',\n",
       " 'comes',\n",
       " 'think about',\n",
       " 'dr jart',\n",
       " 'natural',\n",
       " 'no',\n",
       " 'rules',\n",
       " 'best',\n",
       " 'well for',\n",
       " 'lip',\n",
       " 'hautelook',\n",
       " 'doing the',\n",
       " 'kong',\n",
       " 'codes for',\n",
       " 'mist',\n",
       " 'human',\n",
       " 'hong kong',\n",
       " 'skin barrier',\n",
       " 'co',\n",
       " 'sticking',\n",
       " 'out from',\n",
       " 'it hi',\n",
       " 'personal rules',\n",
       " 'reddit hey',\n",
       " 'boston still',\n",
       " 'from boston',\n",
       " 'hey from',\n",
       " 'of using',\n",
       " 'own personal',\n",
       " 'new to',\n",
       " 'noticing',\n",
       " '99',\n",
       " 'watery essence',\n",
       " 'still trying',\n",
       " 'worst',\n",
       " 'for',\n",
       " 'vitamin and',\n",
       " 'compare',\n",
       " 'can vitamin',\n",
       " 'am looking',\n",
       " 'foot peel',\n",
       " 'hg products',\n",
       " 'much appreciated',\n",
       " 'help remove',\n",
       " 'didn see',\n",
       " 'incorporate',\n",
       " 'aloe sun',\n",
       " 'olens',\n",
       " 'aging and',\n",
       " 'face in',\n",
       " 'nature republic',\n",
       " '2nd cleanser',\n",
       " 'aestura',\n",
       " 'repair',\n",
       " 'is suitable',\n",
       " 'effector',\n",
       " 'ginseng',\n",
       " 'with any',\n",
       " 'pad',\n",
       " 'east',\n",
       " 'pls',\n",
       " 'resistant',\n",
       " 'skincare for',\n",
       " 'routine so',\n",
       " 'at bay',\n",
       " 'bonus',\n",
       " 'concealer',\n",
       " 'leave white',\n",
       " 'emulsions',\n",
       " 'snail essence',\n",
       " 'my skincare',\n",
       " 'combo dehydrated',\n",
       " 'well and',\n",
       " 'greatly appreciate',\n",
       " 'supplement cause',\n",
       " '10000 supplement',\n",
       " 'vitamin 10000',\n",
       " 'have more',\n",
       " 'ulta',\n",
       " 'turn',\n",
       " 'but not',\n",
       " 'out if',\n",
       " 'blogs',\n",
       " 'oc',\n",
       " 'cosrx aha',\n",
       " 'been slathering',\n",
       " 'guys new',\n",
       " 'lip tint',\n",
       " 'sunblock',\n",
       " 'ph',\n",
       " 'it was',\n",
       " 'balancing',\n",
       " 'but no',\n",
       " 'teenager',\n",
       " 'and sunscreen',\n",
       " 'change',\n",
       " 'and currently',\n",
       " 'bio',\n",
       " 'goes',\n",
       " 'reaction on',\n",
       " 'don work',\n",
       " 'disaster',\n",
       " 'tried it',\n",
       " 'primer',\n",
       " 'on ebay',\n",
       " 'is quite',\n",
       " 've also',\n",
       " 'see the',\n",
       " 'faceshop',\n",
       " 'amount',\n",
       " 'searched',\n",
       " 'someone help',\n",
       " 'my local',\n",
       " 'discontinued',\n",
       " 'ordered from',\n",
       " 'nice glow',\n",
       " 'glycol',\n",
       " 'soft',\n",
       " 'water toner',\n",
       " 'hl',\n",
       " 'on that',\n",
       " 'and think',\n",
       " 'mature',\n",
       " 'as above',\n",
       " 'reducing wrinkles',\n",
       " 'that it',\n",
       " 'collection',\n",
       " 'chemical sunscreen',\n",
       " 'high',\n",
       " 'marked',\n",
       " 'show',\n",
       " 'usage',\n",
       " 'vous',\n",
       " 'pcos and',\n",
       " 'zone',\n",
       " 'question has',\n",
       " 'it even',\n",
       " 'how this',\n",
       " 'ascorbyl',\n",
       " 'alcohol is',\n",
       " 'the skin',\n",
       " 'key',\n",
       " 'collagen',\n",
       " 'eyelash extensions',\n",
       " 'analysis',\n",
       " 're breaking',\n",
       " 'and get',\n",
       " 've searched',\n",
       " 'other',\n",
       " 'for free',\n",
       " 'all in',\n",
       " 'applying it',\n",
       " 'an ingredient',\n",
       " 'may cause',\n",
       " 'these two',\n",
       " 'gokujyun',\n",
       " 'looked',\n",
       " 'everyone should',\n",
       " 'joyful',\n",
       " 'mizon joyful',\n",
       " 'red serum',\n",
       " 'found that',\n",
       " 'somewhat',\n",
       " 'my hair',\n",
       " 'prone to',\n",
       " 'face for',\n",
       " 'corner of',\n",
       " 'skin have',\n",
       " 'selling',\n",
       " 'scientific research',\n",
       " 'and there',\n",
       " 'recommend from',\n",
       " 'ost',\n",
       " 'and cream',\n",
       " 'morning routine',\n",
       " 'whitening cream',\n",
       " 'non ab',\n",
       " 'all was',\n",
       " 'grid',\n",
       " 'sha',\n",
       " 'that worked',\n",
       " 'salux',\n",
       " 'power liquid',\n",
       " 'korean brand',\n",
       " 'eyebrow',\n",
       " 'change your',\n",
       " 'cause purging',\n",
       " 'or if',\n",
       " 'toner and',\n",
       " 'popular',\n",
       " 'ask you',\n",
       " 'work any',\n",
       " 'realized my',\n",
       " 'yet but',\n",
       " 'around the',\n",
       " 'from',\n",
       " 'favourite mineral',\n",
       " 'mineral cleansing',\n",
       " 'simply',\n",
       " 'instructions',\n",
       " 'oil mineral',\n",
       " 'amorepacific',\n",
       " 'than sunscreen',\n",
       " 'get that',\n",
       " 'reviews on',\n",
       " 'famous',\n",
       " 'to skincare',\n",
       " 'affecting',\n",
       " 'gua',\n",
       " 'gua sha',\n",
       " 'origin',\n",
       " 'face pimples',\n",
       " 'cysts',\n",
       " 'republic',\n",
       " 'reaction',\n",
       " 'into',\n",
       " 'light',\n",
       " 'the 10',\n",
       " 'where can',\n",
       " 'moisturizing products',\n",
       " 'else have',\n",
       " 'when was',\n",
       " 'but ve',\n",
       " 'for someone',\n",
       " 'have their',\n",
       " 'new here',\n",
       " 'looked into',\n",
       " 'figured',\n",
       " 'know how',\n",
       " 'recommended amount',\n",
       " 'every other',\n",
       " 'get used',\n",
       " 'clearance',\n",
       " '2016',\n",
       " '35',\n",
       " 'your own',\n",
       " 'has pretty',\n",
       " 'skin loves',\n",
       " 'just received',\n",
       " 'corner',\n",
       " 'customer',\n",
       " 'have anyone',\n",
       " '15',\n",
       " 'sensitivity',\n",
       " 'moisturizer have',\n",
       " 'just breakout',\n",
       " 'product to',\n",
       " 'bother',\n",
       " 'havent',\n",
       " 'pulled out',\n",
       " 'great',\n",
       " 'its not',\n",
       " 'condition',\n",
       " 'from the',\n",
       " 'advice ve',\n",
       " 'review',\n",
       " 'up it',\n",
       " 'for us',\n",
       " 'major',\n",
       " 'lemon',\n",
       " 'll be',\n",
       " 'arbutin and',\n",
       " 'to them',\n",
       " 'derma roller',\n",
       " 'of acne',\n",
       " 'fat',\n",
       " 'job',\n",
       " 'taobao',\n",
       " 'products do',\n",
       " 'grid pattern',\n",
       " 'personalized',\n",
       " 'used this',\n",
       " 'centella',\n",
       " 'hi new',\n",
       " 'the dark',\n",
       " 'acnes',\n",
       " 'free to',\n",
       " 'is in',\n",
       " 'barely',\n",
       " 'my questions',\n",
       " 'lotion with',\n",
       " 'cc or',\n",
       " 'grits',\n",
       " 'facial care',\n",
       " 'feel free',\n",
       " 'but its',\n",
       " 'english',\n",
       " 'filipino',\n",
       " 'tried lot',\n",
       " 'work this',\n",
       " 'so here',\n",
       " 'to care',\n",
       " 'self care',\n",
       " 'mask for',\n",
       " 'acwell',\n",
       " 'dye',\n",
       " 'exfoliate',\n",
       " '15 for',\n",
       " 'just starting',\n",
       " '30 off',\n",
       " 'reduce the',\n",
       " 'guys what',\n",
       " 'transino',\n",
       " 'my cosrx',\n",
       " 'before am',\n",
       " 'before use',\n",
       " 'interested in',\n",
       " 'lately',\n",
       " 'apply it',\n",
       " 'recently discovered',\n",
       " 'prone forehead',\n",
       " 'work is',\n",
       " 'do with',\n",
       " 'be very',\n",
       " 'hit',\n",
       " 'hado labo',\n",
       " 'alcohol in',\n",
       " 'discovery',\n",
       " 'know there',\n",
       " 'hado',\n",
       " 'search',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_coef_features = list(coef_df.sort_values('exp_coef', ascending=False)['features'].values)\n",
    "\n",
    "file_name = '../assets/sorted_features_lg_model1.pkl'\n",
    "\n",
    "pickle.dump(sorted_coef_features, open(file_name, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
